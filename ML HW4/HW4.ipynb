{"cells":[{"cell_type":"markdown","metadata":{"id":"Gr4zdOw9pkCU"},"source":["## **HW4 Principal Component Analysis**"]},{"cell_type":"markdown","metadata":{"id":"zhSfW8XWpkCX"},"source":["# 1. Introduction\n","Congratulations on reaching the final assignment! In this assignment, you will learn how to use Principal Components Analysis (PCA) to reduce the dimensionality of high-dimensional data. Additionally, you will compare various differences between the original high-dimensional data and the transformed data obtained through PCA."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PLx_RfeQab4d"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2vLifWpRpkCY"},"outputs":[],"source":["! pip install import_ipynb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lvoW7FrmpkCZ"},"outputs":[],"source":["'''\n","You are not allowed to import other packages\n","\n","If you cannot import the following ipynb file, Please run the ipynb file first and then restart the HW4.ipynb.\n","'''\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import f1_score\n","import math\n","from tqdm import tqdm\n","import time\n","\n","import import_ipynb\n","from PCA import MY_PCA, MY_SparsePCA\n","from Model import *\n","from Loss import *\n","from Utils import *\n","from Data_preprocess import *\n","from Trainer import *\n","from Config import *"]},{"cell_type":"markdown","metadata":{"id":"BeYQuTFqpkCa"},"source":["## Model & Data preprocess"]},{"cell_type":"markdown","metadata":{"id":"xVM0YFNGpkCa"},"source":["As mentioned in Assignment 3, this assignment is closely related to it. Please follow the data preprocessing and model implementation steps from Assignment 3. Note that there are additional constraints on the layer stacking in the model implementation this time. Be sure to follow the prompts for designing the model accordingly.\n","\n","This time, we'll organize different functionalities into separate files for better code readability. For the model and data preprocessing, please implement them in the following files: Loss.ipynb, Model.ipynb, and Data_preprocess.ipynb."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vloO1iWppkCb"},"outputs":[],"source":["X_train, Y_train, X_test = load_data('basic_data.npz')\n","x_train, y_train, x_val, y_val = data_preprocess(X_train, Y_train)"]},{"cell_type":"markdown","metadata":{"id":"ous_bColpkCb"},"source":["# 2. Basic Part"]},{"cell_type":"markdown","metadata":{"id":"s_LapbUfpkCc"},"source":["## PCA Implement\n","In this section, you are required to implement PCA by completing the following steps in the PCA.ipynb file.\n",">* Step1. Centering --> in HW4.ipynb\n",">* Step2. Covariance matrix computation --> in PCA.ipynb\n",">* Step3. Eigenvectors and eigenvalues computation --> in PCA.ipynb\n",">* Step4. Projection --> in PCA.ipynb\n","\n","After implementing PCA, you need to reduce the data to two dimensions, observe the two-dimensional scatter plot of the data, and include it in the report."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QTv9twa-pkCc"},"outputs":[],"source":["# GRADED CODE: Implement centering function. (5%)\n","### START CODE HERE ###\n","'''\n","PCA Step1\n","HINT: It is important to choose the appropriate mean for data centralization..\n","\n","x_train_cent -> Centeralized training data\n","x_val_cent -> Centeralized validation data\n","x_test_cent -> Centeralized testing data\n","'''\n","\n","x_train_cent = None\n","x_val_cent = None\n","X_test_cent = None\n","### END CODE HERE ###"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sNRWK6TBpkCc"},"outputs":[],"source":["# GRADED CODE:\n","# Reduce the dimensions to two and generate scatter plots.\n","# (Training dataset  5%, Validation dataset 5%)\n","\n","### START CODE HERE ###\n","'''\n","x_train_pca -> PCA of training data\n","x_val_pca -> PCA of validation data\n","x_test_pca -> PCA of testing data\n","Please use pca.function(data) to generate PCA of these datasets\n","\n","Parameters:\n","MY_PCA:\n","n_components = Number of components to do the transformation.\n","\n","pca.PCA_visualization:\n","data_pca -> The dataset you want to visuallize.\n","label -> The coresponding labels of the data_pca\n","text -> True if you want to plot the number on the scater plot.\n","tag -> You can set different tag for different figure\n","'''\n","pca = MY_PCA(n_components=2)\n","x_train_pca = None\n","x_val_pca = None\n","x_test_pca = None\n","\n","pca.PCA_visualization(data_pca=None, label=None, text=None, n_components=2, tag=None)\n","### END CODE HERE ###"]},{"cell_type":"markdown","metadata":{"id":"jiHFktMlaVLE"},"source":["The example PCA visuallization of IRIS Datasets.\n","\n","![figure](./iris_pca.png \"IRIS PCA dataset\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kTjDI0owpkCd"},"outputs":[],"source":["# For grading, Please put the basic_cov into your output.npy.\n","basic_cov = pca.covariance_matrix\n","print('covariance_matrix: ', (basic_cov[100][12:16]*10000).round(3))\n","#The reason for multiplying by 10,000 here is that the original values are too small and difficult to observe\n","print(f'x_train_pca:', x_train_pca[0].round(3))\n","print('x_val_pca: ',x_val_pca[0].round(3))"]},{"cell_type":"markdown","metadata":{"id":"j4Nho-l8pkCd"},"source":["**Expected Output**\n","$$ covariance\\_matrix:\\  [0.015\\ \\  0.322\\ \\ 0.322\\ \\ 0.013]$$\n","$$ x\\_train\\_pca:\\ [0.707\\ \\ 3.321]$$\n","$$ x\\_val\\_pca:\\ [-2.295\\  -2.88]$$\n","$$or$$\n","$$ x\\_train\\_pca:\\ [-0.707\\ \\ -3.321]$$\n","$$ x\\_val\\_pca:\\ [2.295\\  2.88]$$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PQPj1Vg3pkCd"},"outputs":[],"source":["# GRADED CODE: TRAINING MODEL WITH PCA DATA (PCA for Training, Validation and Test Dataset)\n","### START CODE HERE ###\n","'''\n","n_components -> Number fo components of PCA, and it will be the input dimension of your basic model.\n","pca -> Define your MY_PCA class here.\n","\n","x_train_pca -> PCA of training data\n","x_val_pca -> PCA of validation data\n","x_test_pca -> PCA of testing data\n","Please use pca.xxx(data) to generate PCA of these datasets\n","'''\n","\n","n_components = None\n","pca = None\n","x_train_pca = None\n","x_val_pca = None\n","x_test_pca = None\n","### END CODE HERE ###\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WeKvtQJnpkCd"},"outputs":[],"source":["# GRADED CODE: PCA INFORMATION REMAIN RATIO PLOT\n","# Calculate the minimum number of principal components to cover 80% variance (5%)\n","### START CODE HERE ###\n","'''\n","num_PC -> Minimum number of principal components to cover 80% variance\n","var_ratio -> The variance ratio of each component\n","'''\n","\n","num_PC, var_ratio = pca.components_remain_ratio(0.80)\n","### END CODE HERE###\n","\n","\n","plt.plot(var_ratio)\n","plt.axvline(x=num_PC, color='r', linestyle='--')\n","\n","plt.text(x=num_PC+3, y=0.02, s='80%', color='r')\n","plt.title('Information Remain Ratio')\n","plt.xlabel('# of Principle Components')\n","plt.ylabel('Remain Ratio of Data')\n","plt.savefig('Infotmation Remaining Ratio.png')\n","plt.show()\n","plt.close()"]},{"cell_type":"markdown","metadata":{"id":"F0uUIbj9aVLF"},"source":["## Reconstruct  Data & Eigenvectors Visuallization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8Ldeb1GlpkCd"},"outputs":[],"source":["\n","\n","# GRADED CODE:\n","# Reconstruct image by using K components and compare with the original image (Training data 5%, Validation data 5%)\n","# Visuallize at least one eigenvector\n","# For grading, please put the reconstruct_data_train and the reconstruct_data_val in output.npy\n","reconstruct_data_train, z_train = pca.reconstructData(x_train[0], np.mean(x_train, axis=0), k=4)\n","reconstruct_data_val, z_val = pca.reconstructData(x_val[0], np.mean(x_train, axis=0), k=4)\n","\n","### START CODE HERE ###\n","'''\n","reconstruct_img -> The reconstruct image of x_train[0].\n","eigenvector_img -> The image of eigenvector\n","'''\n","\n","reconstruct_img = None\n","eigenvector_img = None\n","### END CODE HERE ###\n","\n","plt.imshow(reconstruct_img, cmap='binary')\n","\n","### Please put the reconstruct img in your report\n","plt.savefig('reconstruct_img.png')\n","plt.close()\n","\n","train_squared_reconstruct_error = np.sum(x_train[0] - reconstruct_data_train)**2/reconstruct_data_train.shape[0]\n","val_squared_reconstruct_error = np.sum(x_val[0] - reconstruct_data_val)**2/reconstruct_data_val.shape[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iejLL9ovpkCd"},"outputs":[],"source":["print('k principle components:', num_PC)\n","print('Train Squared Reconstruct Error: ', train_squared_reconstruct_error.round(3))\n","print('Validation Squared Reconstruct Error: ',val_squared_reconstruct_error.round(3))\n","print('z: ', ['%.3f' %(z) for z in z_train])"]},{"cell_type":"markdown","metadata":{"id":"NnB72UUYpkCe"},"source":["**Expected output:**\n","\n","$$ k\\ principle\\ components:  40 $$\n","$$ Train\\ Squared\\ Recontstruct\\ Error:  0.043 $$\n","$$ Validation\\ Squared\\ Reconstruct\\ Error:  0.077 $$\n","$$ z:  [0.707, 3.321, 0.928, 0.603] $$\n","$$or$$\n","$$ z:  [-0.707, -3.321, 0.928, -0.603] $$"]},{"cell_type":"markdown","metadata":{"id":"EsNwAICZpkCe"},"source":["### Model\n","In this part, you need to train your model with low-dimensional data (after PCA) and original data, respectively. Compare the difference between them."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VgeKr5RspkCe"},"outputs":[],"source":["config = Config([x_train.shape[1], 128, 10], 'focal_loss')\n","\n","#CODE: TRAINING MODEL WITHOUT PCA DATA (MODEL SETTING AND TRAINING)\n","\n","# Call Model.ipynb with config to define 'model'\n","# Use Trainer.ipynb to train your model.\n","### START CODE HERE ###\n","None\n","### END CODE HERE ###"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7epRCRENpkCe"},"outputs":[],"source":["pred_train = predict(x_train, y_train, model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T5DAQ5jUpkCe"},"outputs":[],"source":["pred_val = predict(x_val, y_val, model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T_PDS-0lpkCe"},"outputs":[],"source":["config = Config([n_components, 128, 10], 'focal_loss')\n","\n","# GRADED CODE: TRAINING MODEL WITH PCA DATA (MODEL SETTING AND TRAINING)\n","# Use PCA and the model from HW3 (advanced part) to train models on the imbalance MNIST dataset. (10%)\n","\n","# Call Model.ipynb with config to define 'model'\n","# Use Trainer.ipynb to train your model.\n","### START CODE HERE ###\n","None\n","### END CODE HERE ###"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WpVSMc_lpkCe"},"outputs":[],"source":["pred_train = predict(x_train_pca, y_train, model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nXdbX54cpkCe"},"outputs":[],"source":["pred_val = predict(x_val_pca, y_val, model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"37ZJ32j8pkCe"},"outputs":[],"source":["pred_test = predict(x_test_pca, None, model)\n","outputs = {}\n","\n","### for grading\n","outputs[\"basic_pred_test\"] = pred_test\n","outputs[\"basic_layers_dims\"] = config.layers_dims\n","outputs[\"basic_activation_fn\"] = config.activation_fn\n","outputs[\"basic_loss_function\"] = config.loss_function\n","outputs[\"basic_alpha\"] = config.alpha\n","outputs[\"basic_gamma\"] = config.gamma\n","outputs[\"basic_reconstruct_data_train\"] = reconstruct_data_train\n","outputs[\"basic_reconstruct_data_val\"] = reconstruct_data_val\n","outputs[\"basic_covariance_matrix\"] = basic_cov\n","outputs[\"basic_var_ratio\"] = var_ratio\n","basic_model_parameters = []\n","for basic_linear in model.linear:\n","    basic_model_parameters.append(basic_linear.parameters)\n","outputs[\"basic_model_parameters\"] = basic_model_parameters"]},{"cell_type":"markdown","metadata":{"id":"l1Y4-gGvpkCe"},"source":["# 3. Advanced Part"]},{"cell_type":"markdown","metadata":{"id":"vfCmxh4IpkCe"},"source":["In the advanced section, you will learn how to implement non-linear PCA, Sparse PCA.\n","Please complete the PCA.ipynb file for this purpose."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"78LVwm1GpkCe"},"outputs":[],"source":["X_noise_train, Y_noise_train, X_noise_test = load_data('advanced_data.npz')\n","x_noise_train, y_noise_train, x_noise_val, y_noise_val = data_preprocess(X_noise_train, Y_noise_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jc4IanGUaVLI"},"outputs":[],"source":["# GRADED CODE: DATA CENTRALIZATION\n","### START CODE HERE ###\n","'''\n","x_noise_train_cent -> Centeralized training data\n","x_noise_val_cent -> Centeralized validation data\n","x_noise_test_cent -> Centeralized testing data\n","'''\n","x_noise_train_cent = None\n","x_noise_val_cent = None\n","X_noise_test_cent = None\n","### END CODE HERE ###"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mymo_kwRpkCe"},"outputs":[],"source":["# YOU CAN DO PCA HERE TO COMPARE THE PERFORMANCE WITH SPARCEPCA (NOT FOR GRADING)\n","# PCA PART\n","### START CODE HERE ###\n","#PCA PART\n","None\n","\n","#TRAIN WITH ORIGINAL DATA\n","None\n","\n","#TRAIN WITH PCA DATA\n","None\n","\n","### END CODE HERE ###"]},{"cell_type":"markdown","metadata":{"id":"e_j0V7OepkCf"},"source":["### SparsePCA"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uaQm8wD4pkCf"},"outputs":[],"source":["n_components = 2\n","sparse_pca = MY_SparsePCA(n_components, 0.001, 1000)\n","\n","# GRADED CODE: SPARSE PCA IMPLEMENT\n","### START CODE HERE ###\n","'''\n","x_train_spca -> Sparse PCA of training data\n","x_val_spca -> Sparse PCA of validation data\n","x_test_spca -> Sparse PCA of testing data\n","'''\n","x_train_spca = None\n","x_val_spca = None\n","x_test_spca = None\n","### END CODE HERE ###"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YaKLNth0pkCf"},"outputs":[],"source":["### For grading please put sparse_pca_check and sparse_Vt in output.npy\n","sparse_pca_check = x_train_spca\n","sparse_Vt = sparse_pca.Vt[0][0]\n","\n","print('Sparse_pca init Vt: ', sparse_Vt)\n","print('x_train_spca: ', sparse_pca_check[0].round(3))"]},{"cell_type":"markdown","metadata":{"id":"cPifu_98pkCf"},"source":["**Expected Output**\n","$$ Sparse\\_pca\\ init\\ Vt:\\ 1.74160428e^{-20} $$\n","$$ x\\_train\\_spca:\\ [-0.229\\ \\ -0.762]$$"]},{"cell_type":"markdown","metadata":{"id":"QOiP_Sb4aVLK"},"source":["## Sparse PCA imple"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rBgWV8tOpkCf"},"outputs":[],"source":["# GRADED CODE: SPARSE PCA IMPLEMENT\n","### START CODE HERE ###\n","'''\n","n_components -> Number of components fo Sparse PCA, and it will be the input dimension of your basic model.\n","sparse_pca -> Please use\n","x_train_spca -> Sparse PCA of training data\n","x_val_spca -> Sparse PCA of validation data\n","x_test_spca -> Sparse PCA of testing data\n","'''\n","n_components = None\n","sparse_pca = None\n","x_train_spca = None\n","x_val_spca = None\n","x_test_spca = None\n","### END CODE HERE ###"]},{"cell_type":"markdown","metadata":{"id":"WAOkjaeUaVLL"},"source":["## Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"68jwX8Q9pkCf"},"outputs":[],"source":["config = Config([n_components, 64, 10], 'focal_loss')\n","\n","# GRADED CODE: SPARSE PCA IMPLEMENT\n","# Please call Model.ipynb and Trainer.ipynb to define and train your model.\n","### START CODE HERE ###\n","None\n","### END CODE HERE ###"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"37ufPicrpkCf"},"outputs":[],"source":["sparse_pred_train = predict(x_train_spca, y_noise_train, model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FGRpXBDHpkCf"},"outputs":[],"source":["sparse_pred_val = predict(x_val_spca, y_noise_val, model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5TYy_jPoaVLM"},"outputs":[],"source":["sparse_pred_test = predict(x_test_spca, None, model)"]},{"cell_type":"markdown","metadata":{"id":"IW8QfTeppkCg"},"source":["### Advanced Ranking\n","In the advanced ranking section, you are allowed to integrate PCA with additional data preprocessing. However, please note that you are not permitted to use existing data preprocessing and PCA libraries, modify the model's architecture, or alter the predetermined configuration."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"22mgiGxgpkCk"},"outputs":[],"source":["# GRADED CODE: RANKING PART DO YOUR DATA PREPROCESS HERE (10%)\n","## input_dim comment ex. number of  principle components or image dim\n","## loss function = 'focal loss' or 'crossentropy'\n","### START CODE HERE ###\n","'''\n","input_dim -> The first input dimension of your model\n","eg. It could be the number of principle comopnents or original data dimension. Its depends on your data preprocess\n","\n","loss_function -> You can choose the loss function from HW3. (eg. 'focal_loss')\n","'''\n","input_dim = None\n","loss_function = None\n","\n","### END CODE HERE ###"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"weBmleOapkCk"},"outputs":[],"source":["adv_config = Config([input_dim, 128, 10], loss_function)\n","adv_model = Model(adv_config)\n","\n","# GRADED CODE: RANKING PART DO YOUR TRAINING WORK HERE\n","# Please call Trainer.ipynb to train the adv_model.\n","### START CODE HERE ###\n","None\n","adv_pred_test = predict(None, None, adv_model)\n","### END CODE HERE ###"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kJ2FzB9LpkCl"},"outputs":[],"source":["# for grading\n","outputs[\"sparse_Vt\"] = sparse_Vt\n","outputs[\"sparse_pca\"] = sparse_pca_check\n","outputs[\"sparse_pred_train\"] = sparse_pred_train\n","outputs[\"sparse_pred_val\"] = sparse_pred_val\n","outputs[\"sparse_pred_test\"] = sparse_pred_test\n","\n","outputs[\"advanced_pred_test\"] = adv_pred_test\n","outputs[\"advanced_layers_dims\"] = adv_config.layers_dims\n","outputs[\"advanced_activation_fn\"] = adv_config.activation_fn\n","outputs[\"advanced_loss_function\"] = adv_config.loss_function\n","outputs[\"advanced_alpha\"] = adv_config.alpha\n","outputs[\"advanced_gamma\"] = adv_config.gamma\n","\n","\n","advanced_model_parameters = []\n","for advanced_linear in adv_model.linear:\n","    advanced_model_parameters.append(advanced_linear.parameters)\n","outputs[\"advanced_model_parameters\"] = advanced_model_parameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hUby8TzUpkCl"},"outputs":[],"source":["# sanity check\n","assert list(outputs.keys()) == [\n","    'basic_pred_test',\\\n","    'basic_layers_dims',\\\n","    'basic_activation_fn',\\\n","    'basic_loss_function',\\\n","    'basic_alpha',\\\n","    'basic_gamma',\\\n","    'basic_reconstruct_data_train',\\\n","    'basic_reconstruct_data_val',\\\n","    'basic_covariance_matrix',\\\n","    'basic_var_ratio',\\\n","    'basic_model_parameters',\\\n","    'sparse_Vt',\\\n","    'sparse_pca',\\\n","    'sparse_pred_train',\\\n","    'sparse_pred_val',\\\n","    'sparse_pred_test',\\\n","    'advanced_pred_test',\\\n","    'advanced_layers_dims',\\\n","    'advanced_activation_fn',\\\n","    'advanced_loss_function',\\\n","    'advanced_alpha',\\\n","    'advanced_gamma',\\\n","    'advanced_model_parameters'],\\\n","\"You're missing something, please restart the kernel and run the code from begining to the end. If the same error occurs, maybe you deleted some outputs, check the template to find the missing parts!\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sPrjpchApkCl"},"outputs":[],"source":["np.save(\"output.npy\", outputs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IWS0c4IkpkCl"},"outputs":[],"source":["# sanity check\n","submit = np.load(\"output.npy\", allow_pickle=True).item()\n","for key, value in submit.items():\n","    print(str(key) + \"ï¼š \" + str(type(value)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e1eaeV-8pkCm"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"vscode":{"interpreter":{"hash":"bc07a8c6aa785ccbb5cb0815abffaffb139b111aca417c4ffe9bf221bae76ba2"}}},"nbformat":4,"nbformat_minor":0}
